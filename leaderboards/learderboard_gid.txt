{
    "data": [
        {
            "mAP": 0.645,
            "rural_residential": 0.755,
            "arbor_woodland": 0.685,
            "paddy_field": 0.586,
            "irrigated_land": 0.867,
            "pond": 0.285,
            "TeamNames": "lucfy",
            "lake": 0.852,
            "traffic_land": 0.766,
            "urban_residential": 0.811,
            "TeamMembers": "yangzhe",
            "description": "We use volo and segformer as the backbone and design an effective sliding window method to evaluate the large image. Special data augmentation is used for aerial images. No external data is used. A single model is used and model ensemble is not used. A strong data augmentation is used. IoU loss is used. Fda with test images is used. SWA is used to merge models. Two segformer model and one volo model is merged. Train and val data is used.\r\nWe trained a 2-class classifier to solve \r\nshrubland bias and a post process to solve the wrong prediction when lake or river area is too large.",
            "Institute": "Ailbaba",
            "artificial_grassland": 0.246,
            "natural_grassland": 0.845,
            "date": "2021-08-13 10:14:39.045101",
            "shrub_land": 0.34,
            "industrial_land": 0.756,
            "dry_cropland": 0.685,
            "created_date": "2021-08-13 10:14:39.045101",
            "river": 0.741,
            "garden_plot": 0.452
        },
        {
            "mAP": 0.617,
            "rural_residential": 0.755,
            "arbor_woodland": 0.708,
            "paddy_field": 0.586,
            "irrigated_land": 0.867,
            "pond": 0.285,
            "TeamNames": "yuqiuying",
            "lake": 0.803,
            "traffic_land": 0.766,
            "urban_residential": 0.811,
            "TeamMembers": "yuqiuying",
            "description": "merge3",
            "Institute": "NWPU",
            "artificial_grassland": 0.226,
            "natural_grassland": 0.844,
            "date": "2021-08-12 07:38:52.979831",
            "shrub_land": 0.066,
            "industrial_land": 0.756,
            "dry_cropland": 0.685,
            "created_date": "2021-08-12 07:38:52.979831",
            "river": 0.65,
            "garden_plot": 0.452
        },
        {
            "mAP": 0.608,
            "rural_residential": 0.724,
            "arbor_woodland": 0.69,
            "paddy_field": 0.542,
            "irrigated_land": 0.819,
            "pond": 0.279,
            "TeamNames": "GLADOS",
            "lake": 0.803,
            "traffic_land": 0.766,
            "urban_residential": 0.814,
            "TeamMembers": "yuqiuying",
            "description": "813-1",
            "Institute": "NWPU",
            "artificial_grassland": 0.23,
            "natural_grassland": 0.841,
            "date": "2021-08-13 14:18:30.704620",
            "shrub_land": 0.244,
            "industrial_land": 0.706,
            "dry_cropland": 0.57,
            "created_date": "2021-08-13 14:18:30.704620",
            "river": 0.65,
            "garden_plot": 0.452
        },
        {
            "mAP": 0.606,
            "rural_residential": 0.757,
            "arbor_woodland": 0.703,
            "paddy_field": 0.539,
            "irrigated_land": 0.844,
            "pond": 0.265,
            "TeamNames": "yuqiuyinginging",
            "lake": 0.797,
            "traffic_land": 0.77,
            "urban_residential": 0.812,
            "TeamMembers": "liyu",
            "description": "result_merge",
            "Institute": "NWPU",
            "artificial_grassland": 0.227,
            "natural_grassland": 0.846,
            "date": "2021-08-11 15:09:59.310222",
            "shrub_land": 0.068,
            "industrial_land": 0.759,
            "dry_cropland": 0.619,
            "created_date": "2021-08-11 15:09:59.310222",
            "river": 0.65,
            "garden_plot": 0.438
        },
        {
            "mAP": 0.6,
            "rural_residential": 0.742,
            "arbor_woodland": 0.677,
            "paddy_field": 0.586,
            "irrigated_land": 0.866,
            "pond": 0.285,
            "TeamNames": "Alisa",
            "lake": 0.798,
            "traffic_land": 0.751,
            "urban_residential": 0.795,
            "TeamMembers": "Zhou Xuan, Guo Zhi Qing, Liu Wei",
            "description": "0806",
            "Institute": "deep science cn",
            "artificial_grassland": 0.131,
            "natural_grassland": 0.824,
            "date": "2021-08-06 03:04:24.746643",
            "shrub_land": 0.055,
            "industrial_land": 0.742,
            "dry_cropland": 0.686,
            "created_date": "2021-08-06 03:04:24.746643",
            "river": 0.634,
            "garden_plot": 0.422
        },
        {
            "mAP": 0.598,
            "rural_residential": 0.757,
            "arbor_woodland": 0.706,
            "paddy_field": 0.535,
            "irrigated_land": 0.827,
            "pond": 0.246,
            "TeamNames": "yuqiuyinging",
            "lake": 0.799,
            "traffic_land": 0.751,
            "urban_residential": 0.809,
            "TeamMembers": "yuqiuying",
            "description": "volo_16",
            "Institute": "hzau",
            "artificial_grassland": 0.193,
            "natural_grassland": 0.842,
            "date": "2021-08-08 17:39:12.326028",
            "shrub_land": 0.066,
            "industrial_land": 0.758,
            "dry_cropland": 0.59,
            "created_date": "2021-08-08 17:39:12.326028",
            "river": 0.649,
            "garden_plot": 0.438
        },
        {
            "mAP": 0.579,
            "rural_residential": 0.703,
            "arbor_woodland": 0.726,
            "paddy_field": 0.597,
            "irrigated_land": 0.806,
            "pond": 0.26,
            "TeamNames": "wanghao",
            "lake": 0.786,
            "traffic_land": 0.688,
            "urban_residential": 0.775,
            "TeamMembers": "Hao Wang, Jiahao Wang, Zhuojun Dong",
            "description": "n terms of data processing, the labels in the background of the labeled graph are removed, and the corresponding training set is produced for training. We have used the deeplabv3 model for training and used the weighted CE loss as our loss function, and the data are cropped by using a crop of 256 size, and operations such as data enhancement and TTA are performed. this is the first submission, and the next submission will be described in more detail, thank you.",
            "Institute": "Xidian University, IPIU Lab",
            "artificial_grassland": 0.127,
            "natural_grassland": 0.654,
            "date": "2021-08-11 13:47:58.717498",
            "shrub_land": 0.348,
            "industrial_land": 0.706,
            "dry_cropland": 0.557,
            "created_date": "2021-08-11 13:47:58.717498",
            "river": 0.623,
            "garden_plot": 0.323
        },
        {
            "mAP": 0.572,
            "rural_residential": 0.703,
            "arbor_woodland": 0.707,
            "paddy_field": 0.591,
            "irrigated_land": 0.806,
            "pond": 0.251,
            "TeamNames": "hao",
            "lake": 0.796,
            "traffic_land": 0.689,
            "urban_residential": 0.775,
            "TeamMembers": "Hao Wang",
            "description": "In terms of data processing, the labels in the background of the labeled graph are removed, and the corresponding training set is produced for training. We have used the deeplabv3 model for training and used the weighted CE loss as our loss function, and the data are cropped by using a crop of 256 size, and operations such as data enhancement and TTA are performed. this is the first submission, and the next submission will be described in more detail, thank you.",
            "Institute": "NUC University",
            "artificial_grassland": 0.132,
            "natural_grassland": 0.69,
            "date": "2021-08-07 15:12:05.722798",
            "shrub_land": 0.225,
            "industrial_land": 0.706,
            "dry_cropland": 0.557,
            "created_date": "2021-08-07 15:12:05.722798",
            "river": 0.635,
            "garden_plot": 0.322
        },
        {
            "mAP": 0.567,
            "rural_residential": 0.721,
            "arbor_woodland": 0.695,
            "paddy_field": 0.55,
            "irrigated_land": 0.819,
            "pond": 0.23,
            "TeamNames": "dong",
            "lake": 0.792,
            "traffic_land": 0.673,
            "urban_residential": 0.781,
            "TeamMembers": "JunDong",
            "description": "In terms of data processing, the labels in the background of the labeled graph are removed, and the corresponding training set is produced for training. We have used the deeplabv3 model for training and used the weighted CE loss as our loss function, and the data are cropped by using a crop of 256 size, and operations such as data enhancement and TTA are performed. this is the first submission, and the next submission will be described in more detail, thank you.",
            "Institute": "NUC University",
            "artificial_grassland": 0.133,
            "natural_grassland": 0.694,
            "date": "2021-08-12 13:48:00.845570",
            "shrub_land": 0.157,
            "industrial_land": 0.709,
            "dry_cropland": 0.595,
            "created_date": "2021-08-12 13:48:00.845570",
            "river": 0.637,
            "garden_plot": 0.325
        },
        {
            "mAP": 0.567,
            "rural_residential": 0.71,
            "arbor_woodland": 0.701,
            "paddy_field": 0.512,
            "irrigated_land": 0.815,
            "pond": 0.244,
            "TeamNames": "guer",
            "lake": 0.777,
            "traffic_land": 0.654,
            "urban_residential": 0.776,
            "TeamMembers": "guchegnming mengchang zhuyuhen",
            "description": "We are the participating team of Xidian University, and we are honored to participate in this remote sensing image semantic segmentation competition. We use Deeplabv3 +, Backbone uses Resnet101, loss uses CE, and the learning rate is reduced from 0.001 adaptively. We use the 512*512 chopping method.",
            "Institute": "xidian university",
            "artificial_grassland": 0.196,
            "natural_grassland": 0.699,
            "date": "2021-08-14 13:48:53.495853",
            "shrub_land": 0.252,
            "industrial_land": 0.716,
            "dry_cropland": 0.556,
            "created_date": "2021-08-14 13:48:53.495853",
            "river": 0.608,
            "garden_plot": 0.287
        },
        {
            "mAP": 0.567,
            "rural_residential": 0.71,
            "arbor_woodland": 0.701,
            "paddy_field": 0.512,
            "irrigated_land": 0.815,
            "pond": 0.244,
            "TeamNames": "mcer",
            "lake": 0.777,
            "traffic_land": 0.654,
            "urban_residential": 0.776,
            "TeamMembers": "Meng Chang, Hui Yimin, Zhang Jie",
            "description": "We are the participating team of Xidian University, and we are honored to participate in this remote sensing image semantic segmentation competition. We use Deeplabv3 +, Backbone uses Resnet101, loss uses CE, and the learning rate is reduced from 0.001 adaptively. We use the 512*512 chopping method.",
            "Institute": "xidian university",
            "artificial_grassland": 0.196,
            "natural_grassland": 0.699,
            "date": "2021-08-12 13:48:35.965330",
            "shrub_land": 0.252,
            "industrial_land": 0.716,
            "dry_cropland": 0.556,
            "created_date": "2021-08-12 13:48:35.965330",
            "river": 0.608,
            "garden_plot": 0.287
        },
        {
            "mAP": 0.562,
            "rural_residential": 0.698,
            "arbor_woodland": 0.69,
            "paddy_field": 0.517,
            "irrigated_land": 0.815,
            "pond": 0.24,
            "TeamNames": "yanxper",
            "lake": 0.771,
            "traffic_land": 0.649,
            "urban_residential": 0.774,
            "TeamMembers": "Yan Xupen, Gu Chegnming, Lan Yuxuan",
            "description": "We are the participating team of Xidian University, and we are honored to participate in this remote sensing image semantic segmentation competition. We use Deeplabv3 +, Backbone uses Resnet101, loss uses CE, and the learning rate is reduced from 0.001 adaptively. We use the 512*512 chopping method.",
            "Institute": "xidian university",
            "artificial_grassland": 0.196,
            "natural_grassland": 0.685,
            "date": "2021-08-12 05:01:52.121661",
            "shrub_land": 0.252,
            "industrial_land": 0.714,
            "dry_cropland": 0.556,
            "created_date": "2021-08-12 05:01:52.121661",
            "river": 0.604,
            "garden_plot": 0.265
        },
        {
            "mAP": 0.558,
            "rural_residential": 0.736,
            "arbor_woodland": 0.681,
            "paddy_field": 0.537,
            "irrigated_land": 0.822,
            "pond": 0.213,
            "TeamNames": "zds",
            "lake": 0.787,
            "traffic_land": 0.728,
            "urban_residential": 0.773,
            "TeamMembers": "zds",
            "description": "We propose a U-shaped model, which uses Resnet50 as the backbone network to sample the feature fusion module on top.For the shallow input we use High Frequcency Extractor (HFE) to extract the High frequency information of the image,At the same time, Muti-scale Convolution (MSC) is used to filter out unnecessary high-frequency signals so as to optimize cloud edges.For deep input, we use improved Spatial Prior self-attention (SPSA) mechanism to obtain distance information between classes, so as to strengthen the model's control over global information and make the model have better Spatial adaptability.In addition, we introduce Spatial Channel Attention Block (SCAB) to reduce the proportion of redundant information in the feature map. In order to make the model converge better and faster, we adopt the idea of skipping connection in the design of several modules.Using multiple Loss simultaneously for supervised learning. Our device is a single sheet RTX3080 with a video memory capacity of 10G and a batchsize of 4. Our initial learning rate is set as 0.01, Poly learning rate attenuation strategy is adopted, and SGD optimizer is used. A total of 200 iterations are carried out.",
            "Institute": "Nanjing University of Information Science and Technology",
            "artificial_grassland": 0.102,
            "natural_grassland": 0.753,
            "date": "2021-07-25 07:55:17.637329",
            "shrub_land": 0.097,
            "industrial_land": 0.694,
            "dry_cropland": 0.598,
            "created_date": "2021-07-25 07:55:17.637329",
            "river": 0.589,
            "garden_plot": 0.265
        },
        {
            "mAP": 0.552,
            "rural_residential": 0.644,
            "arbor_woodland": 0.686,
            "paddy_field": 0.562,
            "irrigated_land": 0.848,
            "pond": 0.195,
            "TeamNames": "lxcer",
            "lake": 0.782,
            "traffic_land": 0.594,
            "urban_residential": 0.713,
            "TeamMembers": "Liu Xiancheng, Zhang Yongle, Zhao Wengbo",
            "description": "We are the participating team of Xidian University, and we are honored to participate in this remote sensing image semantic segmentation competition. We use Deeplabv3 +, Backbone uses Resnet101, loss uses CE, and the learning rate is reduced from 0.001 adaptively. We use the 512*512 chopping method.",
            "Institute": "xidian university",
            "artificial_grassland": 0.17,
            "natural_grassland": 0.662,
            "date": "2021-08-09 02:33:17.713737",
            "shrub_land": 0.206,
            "industrial_land": 0.634,
            "dry_cropland": 0.654,
            "created_date": "2021-08-09 02:33:17.713737",
            "river": 0.613,
            "garden_plot": 0.323
        },
        {
            "mAP": 0.535,
            "rural_residential": 0.683,
            "arbor_woodland": 0.652,
            "paddy_field": 0.506,
            "irrigated_land": 0.789,
            "pond": 0.226,
            "TeamNames": "xiaowangzz",
            "lake": 0.796,
            "traffic_land": 0.64,
            "urban_residential": 0.771,
            "TeamMembers": "\u9ad8\u5b50\u6db5",
            "description": "We adopt deeplabv3+(https://arxiv.org/pdf/1802.02611.pdf) as our base method, pertained from Cityscapes,\r\n(see https://github.com/jfzhang95/pytorch-deeplab-xception)\r\nDeeplabV3+ is a very popular method in image segmentation, it applied atrous convolution, which allows us to effectively enlarge the field of view of filters to incorporate multi-scale context and a powerful tool that allows us to explicitly control the resolution of features computed by deep convolutional neural networks and adjust filter\u2019s field-of-view in order to capture multi-scale information, generalizes standard convolution operation.  And we split each image in GID into 100 pieces, fine-tuning batch normalization parameters when output stride = 16, and random scale data augmentation during training. Note that we also include batch normalization parameters in the proposed decoder module. Other image augmentation methods have also been adopted. when using ResNet-101 as network backbone in the DeepLabv3+ model. Thanks to atrous convolution, we are able to obtain features at different resolutions during training and evaluation using a single model.",
            "Institute": "Xidian",
            "artificial_grassland": 0.09,
            "natural_grassland": 0.679,
            "date": "2021-08-12 12:00:08.011352",
            "shrub_land": 0.071,
            "industrial_land": 0.701,
            "dry_cropland": 0.54,
            "created_date": "2021-08-12 12:00:08.011352",
            "river": 0.604,
            "garden_plot": 0.272
        },
        {
            "mAP": 0.53,
            "rural_residential": 0.685,
            "arbor_woodland": 0.699,
            "paddy_field": 0.509,
            "irrigated_land": 0.773,
            "pond": 0.223,
            "TeamNames": "pku__lizhou",
            "lake": 0.755,
            "traffic_land": 0.568,
            "urban_residential": 0.758,
            "TeamMembers": "\u674e\u6d32",
            "description": "This question is occasionally mentioned when interviewing for a position in medical imaging algorithms. I offer some personal thoughts here. There are two keywords in the question, [UNet] and [medical imaging]. Let's analyze these two keywords one by one. First of all, let's talk about [UNet]. UNet was first published on MICCAI in 2015, in a short period of 3 years, the citation has reached 4070, which is enough to see its influence. Then it becomes the baseline which mostly does the task of semantic segmentation of medical images, and also inspires a large number of researchers to think about the U-shaped semantic segmentation network. Nowadays, in natural image understanding, more and more semantic segmentation and target detection SOTA models begin to pay attention to and use U-shaped structures, such as semantic segmentation Discriminative Feature Network (DFN) (CVPR2018), target detection Feature Pyramid Networks for Object Detection (FPN) (CVPR 2017) and so on. Let's get back to the point. UNet is just a code name for a network structure. Let's look into the details. What components does UNet consist of?",
            "Institute": "pku",
            "artificial_grassland": 0.147,
            "natural_grassland": 0.606,
            "date": "2021-08-14 12:52:22.361864",
            "shrub_land": 0.187,
            "industrial_land": 0.663,
            "dry_cropland": 0.535,
            "created_date": "2021-08-14 12:52:22.361864",
            "river": 0.582,
            "garden_plot": 0.267
        },
        {
            "mAP": 0.516,
            "rural_residential": 0.634,
            "arbor_woodland": 0.642,
            "paddy_field": 0.503,
            "irrigated_land": 0.766,
            "pond": 0.207,
            "TeamNames": "sjzhao",
            "lake": 0.751,
            "traffic_land": 0.66,
            "urban_residential": 0.761,
            "TeamMembers": "13151586369",
            "description": "ocrnet+hr48",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.128,
            "natural_grassland": 0.672,
            "date": "2021-08-06 11:21:03.900995",
            "shrub_land": 0.061,
            "industrial_land": 0.631,
            "dry_cropland": 0.456,
            "created_date": "2021-08-06 11:21:03.900995",
            "river": 0.56,
            "garden_plot": 0.302
        },
        {
            "mAP": 0.513,
            "rural_residential": 0.711,
            "arbor_woodland": 0.68,
            "paddy_field": 0.558,
            "irrigated_land": 0.722,
            "pond": 0.242,
            "TeamNames": "IPIU_Marco",
            "lake": 0.801,
            "traffic_land": 0.605,
            "urban_residential": 0.771,
            "TeamMembers": "\u9a6c\u5929\u690d\uff0c \u9ad8\u5b50\u6db5\uff0c \u738b\u6ce0\u742a\uff0c\u5de6\u8c0a",
            "description": "5 Inherit the idea of FCN and continue to improve. However, there are several changes compared with FCN, U-Net is completely symmetrical, and the decoder (the concept of encoder and decoder should be put forward by Hinton, that is, the process of image-> high-semantic feature map as encoder, and the process of high-semantic-> pixel-level classification score map as decoder) is deepened by convolution, and FCN only carries out up-sampling.\r\nSkip connection: both use such a structure, although it seems to be quite common now, but at that time, the obvious benefits of such a structure were obvious to all, because it could combine high-level semantics with low-level fine-grained surface information, which well met the needs of segmentation for these two aspects of information.\r\nUnion: in FCN, the union of Skip connection is through the summation of the corresponding pixels, while U-Net is the concat process of its channel.",
            "Institute": "XDU",
            "artificial_grassland": 0.079,
            "natural_grassland": 0.593,
            "date": "2021-08-11 01:14:45.817319",
            "shrub_land": 0.038,
            "industrial_land": 0.684,
            "dry_cropland": 0.414,
            "created_date": "2021-08-11 01:14:45.817319",
            "river": 0.609,
            "garden_plot": 0.191
        },
        {
            "mAP": 0.511,
            "rural_residential": 0.712,
            "arbor_woodland": 0.673,
            "paddy_field": 0.558,
            "irrigated_land": 0.717,
            "pond": 0.239,
            "TeamNames": "deepblue_baijieying",
            "lake": 0.801,
            "traffic_land": 0.605,
            "urban_residential": 0.771,
            "TeamMembers": "\u738b\u6dd9",
            "description": "Inherit the idea of FCN and continue to improve. However, there are several changes compared with FCN, U-Net is completely symmetrical, and the decoder (the concept of encoder and decoder should be put forward by Hinton, that is, the process of image-> high-semantic feature map as encoder, and the process of high-semantic-> pixel-level classification score map as decoder) is deepened by convolution, and FCN only carries out up-sampling.\r\nSkip connection: both use such a structure, although it seems to be quite common now, but at that time, the obvious benefits of such a structure were obvious to all, because it could combine high-level semantics with low-level fine-grained surface information, which well met the needs of segmentation for these two aspects of information.\r\nUnion: in FCN, the union of Skip connection is through the summation of the corresponding pixels, while U-Net is the concat process of its channel.",
            "Institute": "apple",
            "artificial_grassland": 0.079,
            "natural_grassland": 0.593,
            "date": "2021-08-12 11:22:27.475632",
            "shrub_land": 0.038,
            "industrial_land": 0.684,
            "dry_cropland": 0.397,
            "created_date": "2021-08-12 11:22:27.475632",
            "river": 0.609,
            "garden_plot": 0.193
        },
        {
            "mAP": 0.511,
            "rural_residential": 0.631,
            "arbor_woodland": 0.638,
            "paddy_field": 0.505,
            "irrigated_land": 0.763,
            "pond": 0.207,
            "TeamNames": "mf1923099",
            "lake": 0.742,
            "traffic_land": 0.678,
            "urban_residential": 0.77,
            "TeamMembers": "1,2,3,4",
            "description": "ocr48+ms",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.129,
            "natural_grassland": 0.646,
            "date": "2021-08-13 03:06:37.993625",
            "shrub_land": 0.026,
            "industrial_land": 0.622,
            "dry_cropland": 0.477,
            "created_date": "2021-08-13 03:06:37.993625",
            "river": 0.549,
            "garden_plot": 0.282
        },
        {
            "mAP": 0.51,
            "rural_residential": 0.598,
            "arbor_woodland": 0.605,
            "paddy_field": 0.51,
            "irrigated_land": 0.769,
            "pond": 0.2,
            "TeamNames": "thptai",
            "lake": 0.796,
            "traffic_land": 0.607,
            "urban_residential": 0.766,
            "TeamMembers": "Tran Huu Phuong Tai",
            "description": "Our method uses OCR_HRNet_MScales network as the base method to work on.\r\nThe training images are divided into multiple smaller images. The reason is to take the advantages of multiscale training while being able to train with high resolution. The network is trained with 9 different scales (0.25,0.5,1.0,2.0,2.5,3.0,3.5,4.0). \r\nFor the details of dividing raw images, we split an input image into 113 smaller parts with resolution 900x850. We slide the 900x850 mask over the image with the stride [450, 425] for x and y axis respectively.\r\nThe post processing stage is combining multiple smaller results images into one single images. The smoothing process is also applied to the final outputs to improve the overall quality to makeup for the dividing step in the beginning.",
            "Institute": "Sungkyunkwan University",
            "artificial_grassland": 0.139,
            "natural_grassland": 0.607,
            "date": "2021-08-11 08:11:08.869391",
            "shrub_land": 0.032,
            "industrial_land": 0.689,
            "dry_cropland": 0.465,
            "created_date": "2021-08-11 08:11:08.869391",
            "river": 0.621,
            "garden_plot": 0.252
        },
        {
            "mAP": 0.51,
            "rural_residential": 0.668,
            "arbor_woodland": 0.566,
            "paddy_field": 0.506,
            "irrigated_land": 0.767,
            "pond": 0.225,
            "TeamNames": "lingling",
            "lake": 0.796,
            "traffic_land": 0.63,
            "urban_residential": 0.767,
            "TeamMembers": "matianzhi gaozihan wanglingqi zuoyi",
            "description": "Inherit the idea of FCN and continue to improve. However, there are several changes compared with FCN, U-Net is completely symmetrical, and the decoder (the concept of encoder and decoder should be put forward by Hinton, that is, the process of image-> high-semantic feature map as encoder, and the process of high-semantic-> pixel-level classification score map as decoder) is deepened by convolution, and FCN only carries out up-sampling.\r\nSkip connection: both use such a structure, although it seems to be quite common now, but at that time, the obvious benefits of such a structure were obvious to all, because it could combine high-level semantics with low-level fine-grained surface information, which well met the needs of segmentation for these two aspects of information.\r\nUnion: in FCN, the union of Skip connection is through the summation of the corresponding pixels, while U-Net is the concat process of its channel.",
            "Institute": "cn",
            "artificial_grassland": 0.09,
            "natural_grassland": 0.458,
            "date": "2021-08-13 15:56:33.222245",
            "shrub_land": 0.071,
            "industrial_land": 0.696,
            "dry_cropland": 0.538,
            "created_date": "2021-08-13 15:56:33.222245",
            "river": 0.6,
            "garden_plot": 0.272
        },
        {
            "mAP": 0.504,
            "rural_residential": 0.611,
            "arbor_woodland": 0.631,
            "paddy_field": 0.5,
            "irrigated_land": 0.782,
            "pond": 0.217,
            "TeamNames": "gaoziteng",
            "lake": 0.819,
            "traffic_land": 0.63,
            "urban_residential": 0.76,
            "TeamMembers": "a,b,c,d",
            "description": "fusion results",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.037,
            "natural_grassland": 0.578,
            "date": "2021-08-11 12:01:18.502128",
            "shrub_land": 0.006,
            "industrial_land": 0.672,
            "dry_cropland": 0.439,
            "created_date": "2021-08-11 12:01:18.502128",
            "river": 0.64,
            "garden_plot": 0.243
        },
        {
            "mAP": 0.501,
            "rural_residential": 0.63,
            "arbor_woodland": 0.626,
            "paddy_field": 0.427,
            "irrigated_land": 0.802,
            "pond": 0.223,
            "TeamNames": "yixinzhishui",
            "lake": 0.781,
            "traffic_land": 0.547,
            "urban_residential": 0.739,
            "TeamMembers": "Jac",
            "description": "The name of our team is yixinzhihui, from the University of Chinese Academy of Sciences. The version submitted this time is a preliminary test version. It mainly uses Efficientnet-b3 as the encoder, Unet as the decoder, and multi classification cross entropy as the loss function. We want to see where the benchwork for this dataset is.my email is xizhihao19@mails.ucas.ac.cn",
            "Institute": "University of Chinese Academy of Sciences",
            "artificial_grassland": 0.029,
            "natural_grassland": 0.609,
            "date": "2021-07-23 03:03:06.218716",
            "shrub_land": 0.068,
            "industrial_land": 0.648,
            "dry_cropland": 0.595,
            "created_date": "2021-07-23 03:03:06.218716",
            "river": 0.619,
            "garden_plot": 0.179
        },
        {
            "mAP": 0.497,
            "rural_residential": 0.614,
            "arbor_woodland": 0.642,
            "paddy_field": 0.501,
            "irrigated_land": 0.734,
            "pond": 0.22,
            "TeamNames": "hyf",
            "lake": 0.781,
            "traffic_land": 0.644,
            "urban_residential": 0.744,
            "TeamMembers": "Yifei Hu",
            "description": "Swin_transformer",
            "Institute": "Alibaba-inc",
            "artificial_grassland": 0.027,
            "natural_grassland": 0.573,
            "date": "2021-08-10 02:50:31.343541",
            "shrub_land": 0.046,
            "industrial_land": 0.684,
            "dry_cropland": 0.362,
            "created_date": "2021-08-10 02:50:31.343541",
            "river": 0.614,
            "garden_plot": 0.268
        },
        {
            "mAP": 0.484,
            "rural_residential": 0.563,
            "arbor_woodland": 0.599,
            "paddy_field": 0.523,
            "irrigated_land": 0.764,
            "pond": 0.153,
            "TeamNames": "zhaosijie",
            "lake": 0.804,
            "traffic_land": 0.525,
            "urban_residential": 0.747,
            "TeamMembers": "Chen Haoran, Hu Yifei, Zhao Sijie",
            "description": "ocrnet h18 1024x1024",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.032,
            "natural_grassland": 0.575,
            "date": "2021-08-13 07:08:24.457260",
            "shrub_land": 0.05,
            "industrial_land": 0.656,
            "dry_cropland": 0.493,
            "created_date": "2021-08-13 07:08:24.457260",
            "river": 0.6,
            "garden_plot": 0.171
        },
        {
            "mAP": 0.44,
            "rural_residential": 0.67,
            "arbor_woodland": 0.661,
            "paddy_field": 0.41,
            "irrigated_land": 0.717,
            "pond": 0.129,
            "TeamNames": "DeepBlueAI",
            "lake": 0.658,
            "traffic_land": 0.635,
            "urban_residential": 0.753,
            "TeamMembers": "ZhiPeng Luo, Ge Li",
            "description": "The method uses deep lab V3 + to segment RGB image semantically. The size of the cut image is 512 * 512 and the length of the sliding side is 256. The test image is cut by the same method. In training, the random clipping size is 449 * 449, the batch size is 48, and the number of iterations is 40K. The data enhancement includes random crop, random flip horizontal, random flip vertical, and photometricdistoration",
            "Institute": "DeepBlue Technology (Shanghai) Co., Ltd",
            "artificial_grassland": 0.05,
            "natural_grassland": 0.596,
            "date": "2021-08-12 12:48:16.176040",
            "shrub_land": 0.011,
            "industrial_land": 0.649,
            "dry_cropland": 0.139,
            "created_date": "2021-08-12 12:48:16.176040",
            "river": 0.456,
            "garden_plot": 0.075
        }
    ]
}