{
    "data": [
        {
            "mAP": 0.645,
            "rural_residential": 0.755,
            "arbor_woodland": 0.685,
            "paddy_field": 0.586,
            "irrigated_land": 0.867,
            "pond": 0.285,
            "TeamNames": "lucfy",
            "lake": 0.852,
            "traffic_land": 0.766,
            "urban_residential": 0.811,
            "TeamMembers": "yangzhe",
            "description": "We use volo and segformer as the backbone and design an effective sliding window method to evaluate the large image. Special data augmentation is used for aerial images. No external data is used. A single model is used and model ensemble is not used. A strong data augmentation is used. IoU loss is used. Fda with test images is used. SWA is used to merge models. Two segformer model and one volo model is merged. Train and val data is used. We trained a 2-class classifier to solve shrubland bias and a post process to solve the wrong prediction when lake or river area is too large.",
            "Institute": "Ailbaba",
            "artificial_grassland": 0.253,
            "natural_grassland": 0.847,
            "date": "2021-08-14 15:48:31.764530",
            "shrub_land": 0.34,
            "industrial_land": 0.756,
            "dry_cropland": 0.685,
            "created_date": "2021-08-14 15:48:31.764530",
            "river": 0.741,
            "garden_plot": 0.452
        },
        {
            "mAP": 0.617,
            "rural_residential": 0.755,
            "arbor_woodland": 0.708,
            "paddy_field": 0.586,
            "irrigated_land": 0.867,
            "pond": 0.285,
            "TeamNames": "yuqiuying",
            "lake": 0.803,
            "traffic_land": 0.766,
            "urban_residential": 0.811,
            "TeamMembers": "yuqiuying",
            "description": "merge3",
            "Institute": "NWPU",
            "artificial_grassland": 0.226,
            "natural_grassland": 0.844,
            "date": "2021-08-12 07:38:52.979831",
            "shrub_land": 0.066,
            "industrial_land": 0.756,
            "dry_cropland": 0.685,
            "created_date": "2021-08-12 07:38:52.979831",
            "river": 0.65,
            "garden_plot": 0.452
        },
        {
            "mAP": 0.608,
            "rural_residential": 0.724,
            "arbor_woodland": 0.69,
            "paddy_field": 0.542,
            "irrigated_land": 0.819,
            "pond": 0.279,
            "TeamNames": "GLADOS",
            "lake": 0.803,
            "traffic_land": 0.766,
            "urban_residential": 0.814,
            "TeamMembers": "yuqiuying",
            "description": "813-1",
            "Institute": "NWPU",
            "artificial_grassland": 0.23,
            "natural_grassland": 0.841,
            "date": "2021-08-13 14:18:30.704620",
            "shrub_land": 0.244,
            "industrial_land": 0.706,
            "dry_cropland": 0.57,
            "created_date": "2021-08-13 14:18:30.704620",
            "river": 0.65,
            "garden_plot": 0.452
        },
        {
            "mAP": 0.606,
            "rural_residential": 0.757,
            "arbor_woodland": 0.703,
            "paddy_field": 0.539,
            "irrigated_land": 0.844,
            "pond": 0.265,
            "TeamNames": "yuqiuyinginging",
            "lake": 0.797,
            "traffic_land": 0.77,
            "urban_residential": 0.812,
            "TeamMembers": "liyu",
            "description": "result_merge",
            "Institute": "NWPU",
            "artificial_grassland": 0.227,
            "natural_grassland": 0.846,
            "date": "2021-08-11 15:09:59.310222",
            "shrub_land": 0.068,
            "industrial_land": 0.759,
            "dry_cropland": 0.619,
            "created_date": "2021-08-11 15:09:59.310222",
            "river": 0.65,
            "garden_plot": 0.438
        },
        {
            "mAP": 0.6,
            "rural_residential": 0.742,
            "arbor_woodland": 0.677,
            "paddy_field": 0.586,
            "irrigated_land": 0.866,
            "pond": 0.285,
            "TeamNames": "Alisa",
            "lake": 0.798,
            "traffic_land": 0.751,
            "urban_residential": 0.795,
            "TeamMembers": "Zhou Xuan, Guo Zhi Qing, Liu Wei",
            "description": "0806",
            "Institute": "deep science cn",
            "artificial_grassland": 0.131,
            "natural_grassland": 0.824,
            "date": "2021-08-06 03:04:24.746643",
            "shrub_land": 0.055,
            "industrial_land": 0.742,
            "dry_cropland": 0.686,
            "created_date": "2021-08-06 03:04:24.746643",
            "river": 0.634,
            "garden_plot": 0.422
        },
        {
            "mAP": 0.598,
            "rural_residential": 0.757,
            "arbor_woodland": 0.706,
            "paddy_field": 0.535,
            "irrigated_land": 0.827,
            "pond": 0.246,
            "TeamNames": "yuqiuyinging",
            "lake": 0.799,
            "traffic_land": 0.751,
            "urban_residential": 0.809,
            "TeamMembers": "yuqiuying",
            "description": "volo_16",
            "Institute": "hzau",
            "artificial_grassland": 0.193,
            "natural_grassland": 0.842,
            "date": "2021-08-08 17:39:12.326028",
            "shrub_land": 0.066,
            "industrial_land": 0.758,
            "dry_cropland": 0.59,
            "created_date": "2021-08-08 17:39:12.326028",
            "river": 0.649,
            "garden_plot": 0.438
        },
        {
            "mAP": 0.59,
            "rural_residential": 0.708,
            "arbor_woodland": 0.713,
            "paddy_field": 0.646,
            "irrigated_land": 0.83,
            "pond": 0.298,
            "TeamNames": "lingling",
            "lake": 0.854,
            "traffic_land": 0.609,
            "urban_residential": 0.773,
            "TeamMembers": "matianzhi gaozihan wanglingqi zuoyi",
            "description": "What's the problem?\r\nSegmentation of medical images.\r\nThe method used?\r\nInherit the idea of FCN and continue to improve. However, there are several changes compared with FCN, U-Net is completely symmetrical, and the decoder (the concept of encoder and decoder should be put forward by Hinton, that is, the process of image-> high-semantic feature map as encoder, and the process of high-semantic-> pixel-level classification score map as decoder) is deepened by convolution, and FCN only carries out up-sampling.\r\nSkip connection: both use such a structure, although it seems to be quite common now, but at that time, the obvious benefits of such a structure were obvious to all, because it could combine high-level semantics with low-level fine-grained surface information, which well met the needs of segmentation for these two aspects of information.\r\nUnion: in FCN, the union of Skip connection is through the summation of the corresponding pixels, while U-Net is the concat process of its channel.",
            "Institute": "cn",
            "artificial_grassland": 0.177,
            "natural_grassland": 0.643,
            "date": "2021-08-16 06:15:26.026246",
            "shrub_land": 0.353,
            "industrial_land": 0.688,
            "dry_cropland": 0.66,
            "created_date": "2021-08-16 06:15:26.026246",
            "river": 0.717,
            "garden_plot": 0.181
        },
        {
            "mAP": 0.582,
            "rural_residential": 0.712,
            "arbor_woodland": 0.701,
            "paddy_field": 0.573,
            "irrigated_land": 0.83,
            "pond": 0.242,
            "TeamNames": "lxcer",
            "lake": 0.785,
            "traffic_land": 0.658,
            "urban_residential": 0.779,
            "TeamMembers": "Liu Xiancheng, Zhang Yongle, Zhao Wengbo",
            "description": "Hello, organizer, we are the participating team of Xidian University. My team name is mcer. The account name is the same as the team name. \u200b\u200b\u200bIt's my honor to participate in this competition. Our team members are Meng Chang(cmeng_1@stu.xidian.edu.cn)\u200b, Hui Yiming(2995652875@qq.com), Zhang Jie(zhagnjie5662@163.com), Zhang Zixiao(zhangzx@stu.xidian.edu.cn) and Jiao Licheng(lchjiao@mail.xidian.edu.cn). After trying out many models for this contest, we decided to use the UNet and Deeplabv3+ networks. The effect of these two networks on GID15 remote sensing image is better than other models. We tried 256, 512 and 1024 clipping methods and used superposition clipping. Backbone has tried resnet and XCeption. Different crop sizes are generally good and bad, but there are subtle differences in single categories. We first cover these results optimally and get better results. The sizes of 512 and 1024 are used for prediction. Then test enhancements were added, including flips and color transformations. Test enhancements did not improve much in this experiment. After the statistical data, it was found that the categories with low MIOU accounted for a small proportion in the training set, and the distribution was unbalanced. To solve the problem of data imbalance, we conducted separate dichotomy training. The results of dichotomies are covered on the forecast map. Multiple predictions were made and voted on for several charts with poor predictions. The final vote is in multiple results.",
            "Institute": "xidian university",
            "artificial_grassland": 0.219,
            "natural_grassland": 0.706,
            "date": "2021-08-16 03:06:56.824236",
            "shrub_land": 0.278,
            "industrial_land": 0.72,
            "dry_cropland": 0.614,
            "created_date": "2021-08-16 03:06:56.824236",
            "river": 0.622,
            "garden_plot": 0.297
        },
        {
            "mAP": 0.581,
            "rural_residential": 0.705,
            "arbor_woodland": 0.727,
            "paddy_field": 0.596,
            "irrigated_land": 0.813,
            "pond": 0.248,
            "TeamNames": "hao",
            "lake": 0.776,
            "traffic_land": 0.686,
            "urban_residential": 0.775,
            "TeamMembers": "Hao Wang",
            "description": "Dear LUAI Sponsor, Hello! Thank you for spending time to read our email.Our current institute is the Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University. Our team members are Hao Wang, Jiahao Wang,Miss Zhuojun Dong,Licheng Jiao,Fang Liu and Qianyue Bao. We would like to try out the evaluation system to evaluate the effect of our submission.At the beginning of the competition, we tried OCR-HRnet, Bisenet and Transformer (TransUnet, Swin-unet) for model training, but the results were not good. After a lot of experiments, we finally chose deeplab series model.We mainly use Deeplabv3+ model for data training,we use the model fusion method and use dichotomous coverage to improve the accuracy of prediction.During the training process, we cropped the image to different sizes for training, so as to improve more features.Backbone (Resnet101, DRN and XCeption) is replaced, and the training set is clipping to 256, 512 and 1024 pixels respectively for training. In the inference stage, the test set is also clipping to different sizes for prediction, and TTA is used to improve the accuracy of the model. Nearly 20 different prediction results were obtained, and the soft voting method was used to integrate the models.",
            "Institute": "NUC University",
            "artificial_grassland": 0.131,
            "natural_grassland": 0.648,
            "date": "2021-08-16 02:51:29.215391",
            "shrub_land": 0.348,
            "industrial_land": 0.707,
            "dry_cropland": 0.623,
            "created_date": "2021-08-16 02:51:29.215391",
            "river": 0.614,
            "garden_plot": 0.322
        },
        {
            "mAP": 0.579,
            "rural_residential": 0.712,
            "arbor_woodland": 0.701,
            "paddy_field": 0.526,
            "irrigated_land": 0.831,
            "pond": 0.24,
            "TeamNames": "mcer",
            "lake": 0.785,
            "traffic_land": 0.658,
            "urban_residential": 0.778,
            "TeamMembers": "Meng Chang, Hui Yimin, Zhang Jie",
            "description": "\u200b Hello, organizer, we are the participating team of Xidian University. My team name is mcer. The account name is the same as the team name. \u200b\u200b\u200bIt's my honor to participate in this competition. Our team members are Meng Chang(cmeng_1@stu.xidian.edu.cn)\u200b, Hui Yiming(2995652875@qq.com), Zhang Jie(zhagnjie5662@163.com), Zhang Zixiao(zhangzx@stu.xidian.edu.cn) and Jiao Licheng(lchjiao@mail.xidian.edu.cn). \r\n\r\n    After trying out many models for this contest, we decided to use the UNet and Deeplabv3+ networks. The effect of these two networks on GID15 remote sensing image is better than other models. We tried 256, 512 and 1024 clipping methods and used superposition clipping. Backbone has tried resnet and XCeption. Different crop sizes are generally good and bad, but there are subtle differences in single categories. We first cover these results optimally and get better results. The sizes of 512 and 1024 are used for prediction. Then test enhancements were added, including flips and color transformations. Test enhancements did not improve much in this experiment. After the statistical data, it was found that the categories with low MIOU accounted for a small proportion in the training set, and the distribution was unbalanced. To solve the problem of data imbalance, we conducted separate dichotomy training. The results of dichotomies are covered on the forecast map. Multiple predictions were made and voted on for several charts with poor predictions. The final vote is in multiple results.",
            "Institute": "xidian university",
            "artificial_grassland": 0.219,
            "natural_grassland": 0.706,
            "date": "2021-08-16 02:38:50.593932",
            "shrub_land": 0.278,
            "industrial_land": 0.72,
            "dry_cropland": 0.614,
            "created_date": "2021-08-16 02:38:50.593932",
            "river": 0.622,
            "garden_plot": 0.297
        },
        {
            "mAP": 0.579,
            "rural_residential": 0.703,
            "arbor_woodland": 0.726,
            "paddy_field": 0.597,
            "irrigated_land": 0.806,
            "pond": 0.26,
            "TeamNames": "wanghao",
            "lake": 0.786,
            "traffic_land": 0.688,
            "urban_residential": 0.775,
            "TeamMembers": "Hao Wang, Jiahao Wang, Zhuojun Dong",
            "description": "n terms of data processing, the labels in the background of the labeled graph are removed, and the corresponding training set is produced for training. We have used the deeplabv3 model for training and used the weighted CE loss as our loss function, and the data are cropped by using a crop of 256 size, and operations such as data enhancement and TTA are performed. this is the first submission, and the next submission will be described in more detail, thank you.",
            "Institute": "Xidian University, IPIU Lab",
            "artificial_grassland": 0.127,
            "natural_grassland": 0.654,
            "date": "2021-08-11 13:47:58.717498",
            "shrub_land": 0.348,
            "industrial_land": 0.706,
            "dry_cropland": 0.557,
            "created_date": "2021-08-11 13:47:58.717498",
            "river": 0.623,
            "garden_plot": 0.323
        },
        {
            "mAP": 0.579,
            "rural_residential": 0.703,
            "arbor_woodland": 0.726,
            "paddy_field": 0.597,
            "irrigated_land": 0.806,
            "pond": 0.258,
            "TeamNames": "dong",
            "lake": 0.786,
            "traffic_land": 0.688,
            "urban_residential": 0.775,
            "TeamMembers": "JunDong",
            "description": "Dear LUAI Sponsor, \r\nHello!  Thank you for spending time to read our email.Our current institute is the Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University. Our team members are Hao Wang, Jiahao Wang,Miss Zhuojun Dong,Licheng Jiao,Fang Liu and Qianyue Bao. We would like to try out the evaluation system to evaluate the effect of our submission.At the beginning of the competition, we tried OCR-HRnet, Bisenet and Transformer (TransUnet, Swin-unet) for model training, but the results were not good. After a lot of experiments, we finally chose deeplab series model.We mainly use Deeplabv3+ model for data training,we use the model fusion method and use dichotomous coverage to improve the accuracy of prediction.During the training process, we cropped the image to different sizes for training, so as to improve more features.Backbone (Resnet101, DRN and XCeption) is replaced, and the training set is clipping to 256, 512 and 1024 pixels respectively for training. In the inference stage, the test set is also clipping to different sizes for prediction, and TTA is used to improve the accuracy of the model. Nearly 20 different prediction results were obtained, and the soft voting method was used to integrate the models.",
            "Institute": "NUC University",
            "artificial_grassland": 0.127,
            "natural_grassland": 0.654,
            "date": "2021-08-16 03:14:21.047691",
            "shrub_land": 0.348,
            "industrial_land": 0.706,
            "dry_cropland": 0.557,
            "created_date": "2021-08-16 03:14:21.047691",
            "river": 0.624,
            "garden_plot": 0.323
        },
        {
            "mAP": 0.574,
            "rural_residential": 0.712,
            "arbor_woodland": 0.694,
            "paddy_field": 0.526,
            "irrigated_land": 0.831,
            "pond": 0.24,
            "TeamNames": "guer",
            "lake": 0.785,
            "traffic_land": 0.658,
            "urban_residential": 0.778,
            "TeamMembers": "guchegnming mengchang zhuyuhen",
            "description": "After trying out many models for this contest, we decided to use the UNet and Deeplabv3+ networks. The effect of these two networks on GID15 remote sensing image is better than other models. We tried 256, 512 and 1024 clipping methods and used superposition clipping. Backbone has tried resnet and XCeption. Different crop sizes are generally good and bad, but there are subtle differences in single categories. We first cover these results optimally and get better results. The sizes of 512 and 1024 are used for prediction. Then test enhancements were added, including flips and color transformations. Test enhancements did not improve much in this experiment. After the statistical data, it was found that the categories with low MIOU accounted for a small proportion in the training set, and the distribution was unbalanced. To solve the problem of data imbalance, we conducted separate dichotomy training. The results of dichotomies are covered on the forecast map. Multiple predictions were made and voted on for several charts with poor predictions. The final vote is in multiple results.",
            "Institute": "xidian university",
            "artificial_grassland": 0.217,
            "natural_grassland": 0.706,
            "date": "2021-08-16 02:10:20.671771",
            "shrub_land": 0.216,
            "industrial_land": 0.72,
            "dry_cropland": 0.61,
            "created_date": "2021-08-16 02:10:20.671771",
            "river": 0.622,
            "garden_plot": 0.298
        },
        {
            "mAP": 0.574,
            "rural_residential": 0.712,
            "arbor_woodland": 0.694,
            "paddy_field": 0.526,
            "irrigated_land": 0.831,
            "pond": 0.24,
            "TeamNames": "yanxper",
            "lake": 0.785,
            "traffic_land": 0.658,
            "urban_residential": 0.778,
            "TeamMembers": "Yan Xupen, Gu Chegnming, Lan Yuxuan",
            "description": "After trying out many models for this contest, we decided to use the UNet and Deeplabv3+ networks. The effect of these two networks on GID15 remote sensing image is better than other models. We tried 256, 512 and 1024 clipping methods and used superposition clipping. Backbone has tried resnet and XCeption. Different crop sizes are generally good and bad, but there are subtle differences in single categories. We first cover these results optimally and get better results. The sizes of 512 and 1024 are used for prediction. Then test enhancements were added, including flips and color transformations. Test enhancements did not improve much in this experiment. After the statistical data, it was found that the categories with low MIOU accounted for a small proportion in the training set, and the distribution was unbalanced. To solve the problem of data imbalance, we conducted separate dichotomy training. The results of dichotomies are covered on the forecast map. Multiple predictions were made and voted on for several charts with poor predictions. The final vote is in multiple results.",
            "Institute": "xidian university",
            "artificial_grassland": 0.217,
            "natural_grassland": 0.706,
            "date": "2021-08-16 02:19:40.690648",
            "shrub_land": 0.216,
            "industrial_land": 0.72,
            "dry_cropland": 0.61,
            "created_date": "2021-08-16 02:19:40.690648",
            "river": 0.622,
            "garden_plot": 0.298
        },
        {
            "mAP": 0.573,
            "rural_residential": 0.708,
            "arbor_woodland": 0.716,
            "paddy_field": 0.519,
            "irrigated_land": 0.789,
            "pond": 0.224,
            "TeamNames": "xiaowangzz",
            "lake": 0.852,
            "traffic_land": 0.608,
            "urban_residential": 0.773,
            "TeamMembers": "\u9ad8\u5b50\u6db5",
            "description": "We adopt deeplabv3+(https://arxiv.org/pdf/1802.02611.pdf) as our base method, pertained from Cityscapes,\r\n(see https://github.com/jfzhang95/pytorch-deeplab-xception)\r\nDeeplabV3+ is a very popular method in image segmentation, it applied atrous convolution, which allows us to effectively enlarge the field of view of filters to incorporate multi-scale context and a powerful tool that allows us to explicitly control the resolution of features computed by deep convolutional neural networks and adjust filter\u2019s field-of-view in order to capture multi-scale information, generalizes standard convolution operation.  And we split each image in GID into 100 pieces, fine-tuning batch normalization parameters when output stride = 16, and random scale data augmentation during training. Note that we also include batch normalization parameters in the proposed decoder module. Other image augmentation methods have also been adopted. when using ResNet-101 as network backbone in the DeepLabv3+ model. Thanks to atrous convolution, we are able to obtain features at different resolutions during training and evaluation using a single model.",
            "Institute": "Xidian",
            "artificial_grassland": 0.177,
            "natural_grassland": 0.638,
            "date": "2021-08-16 00:20:55.638946",
            "shrub_land": 0.353,
            "industrial_land": 0.688,
            "dry_cropland": 0.591,
            "created_date": "2021-08-16 00:20:55.638946",
            "river": 0.71,
            "garden_plot": 0.256
        },
        {
            "mAP": 0.569,
            "rural_residential": 0.708,
            "arbor_woodland": 0.716,
            "paddy_field": 0.519,
            "irrigated_land": 0.789,
            "pond": 0.224,
            "TeamNames": "pku__lizhou",
            "lake": 0.852,
            "traffic_land": 0.608,
            "urban_residential": 0.773,
            "TeamMembers": "\u674e\u6d32",
            "description": "UNet was first published on MICCAI in 2015, in a short period of 3 years, the citation has reached 4070, which is enough to see its influence. Then it becomes the baseline which mostly does the task of semantic segmentation of medical images, and also inspires a large number of researchers to think about the U-shaped semantic segmentation network. Nowadays, in natural image understanding, more and more semantic segmentation and target detection SOTA models begin to pay attention to and use U-shaped structures, such as semantic segmentation Discriminative Feature Network (DFN) (CVPR2018), target detection Feature Pyramid Networks for Object Detection (FPN) (CVPR 2017) and so on. Let's get back to the point. UNet is just a code name for a network structure. Let's take a closer look at it.",
            "Institute": "pku",
            "artificial_grassland": 0.143,
            "natural_grassland": 0.633,
            "date": "2021-08-15 19:06:49.545465",
            "shrub_land": 0.353,
            "industrial_land": 0.688,
            "dry_cropland": 0.564,
            "created_date": "2021-08-15 19:06:49.545465",
            "river": 0.709,
            "garden_plot": 0.256
        },
        {
            "mAP": 0.569,
            "rural_residential": 0.708,
            "arbor_woodland": 0.716,
            "paddy_field": 0.519,
            "irrigated_land": 0.789,
            "pond": 0.224,
            "TeamNames": "IPIU_Marco",
            "lake": 0.851,
            "traffic_land": 0.608,
            "urban_residential": 0.773,
            "TeamMembers": "\u9a6c\u5929\u690d\uff0c \u9ad8\u5b50\u6db5\uff0c \u738b\u6ce0\u742a\uff0c\u5de6\u8c0a",
            "description": "UNet was first published on MICCAI in 2015, in a short period of 3 years, the citation has reached 4070, which is enough to see its influence. Then it becomes the baseline which mostly does the task of semantic segmentation of medical images, and also inspires a large number of researchers to think about the U-shaped semantic segmentation network. Nowadays, in natural image understanding, more and more semantic segmentation and target detection SOTA models begin to pay attention to and use U-shaped structures, such as semantic segmentation Discriminative Feature Network (DFN) (CVPR2018), target detection Feature Pyramid Networks for Object Detection (FPN) (CVPR 2017) and so on. Let's get back to the point. UNet is just a code name for a network structure. Let's take a closer look at it.",
            "Institute": "XDU",
            "artificial_grassland": 0.143,
            "natural_grassland": 0.633,
            "date": "2021-08-15 16:00:22.357225",
            "shrub_land": 0.353,
            "industrial_land": 0.688,
            "dry_cropland": 0.564,
            "created_date": "2021-08-15 16:00:22.357225",
            "river": 0.707,
            "garden_plot": 0.256
        },
        {
            "mAP": 0.569,
            "rural_residential": 0.708,
            "arbor_woodland": 0.716,
            "paddy_field": 0.515,
            "irrigated_land": 0.789,
            "pond": 0.224,
            "TeamNames": "deepblue_baijieying",
            "lake": 0.852,
            "traffic_land": 0.608,
            "urban_residential": 0.773,
            "TeamMembers": "\u738b\u6dd9",
            "description": "First of all, let's talk about [UNet]. UNet was first published on MICCAI in 2015, in a short period of 3 years, the citation has reached 4070, which is enough to see its influence. Then it becomes the baseline which mostly does the task of semantic segmentation of medical images, and also inspires a large number of researchers to think about the U-shaped semantic segmentation network. Nowadays, in natural image understanding, more and more semantic segmentation and target detection SOTA models begin to pay attention to and use U-shaped structures, such as semantic segmentation Discriminative Feature Network (DFN) (CVPR2018), target detection Feature Pyramid Networks for Object Detection (FPN) (CVPR 2017) and so on. Let's get back to the point. UNet is just a code name for a network structure. Let's look into the details. What components does UNet consist of? I think the structure of UNet has two biggest features, U-shaped structure and skip-connection (figure below).",
            "Institute": "apple",
            "artificial_grassland": 0.143,
            "natural_grassland": 0.633,
            "date": "2021-08-15 23:08:10.619791",
            "shrub_land": 0.353,
            "industrial_land": 0.688,
            "dry_cropland": 0.564,
            "created_date": "2021-08-15 23:08:10.619791",
            "river": 0.71,
            "garden_plot": 0.256
        },
        {
            "mAP": 0.558,
            "rural_residential": 0.736,
            "arbor_woodland": 0.681,
            "paddy_field": 0.537,
            "irrigated_land": 0.822,
            "pond": 0.213,
            "TeamNames": "zds",
            "lake": 0.787,
            "traffic_land": 0.728,
            "urban_residential": 0.773,
            "TeamMembers": "zds",
            "description": "We propose a U-shaped model, which uses Resnet50 as the backbone network to sample the feature fusion module on top.For the shallow input we use High Frequcency Extractor (HFE) to extract the High frequency information of the image,At the same time, Muti-scale Convolution (MSC) is used to filter out unnecessary high-frequency signals so as to optimize cloud edges.For deep input, we use improved Spatial Prior self-attention (SPSA) mechanism to obtain distance information between classes, so as to strengthen the model's control over global information and make the model have better Spatial adaptability.In addition, we introduce Spatial Channel Attention Block (SCAB) to reduce the proportion of redundant information in the feature map. In order to make the model converge better and faster, we adopt the idea of skipping connection in the design of several modules.Using multiple Loss simultaneously for supervised learning. Our device is a single sheet RTX3080 with a video memory capacity of 10G and a batchsize of 4. Our initial learning rate is set as 0.01, Poly learning rate attenuation strategy is adopted, and SGD optimizer is used. A total of 200 iterations are carried out.",
            "Institute": "Nanjing University of Information Science and Technology",
            "artificial_grassland": 0.102,
            "natural_grassland": 0.753,
            "date": "2021-07-25 07:55:17.637329",
            "shrub_land": 0.097,
            "industrial_land": 0.694,
            "dry_cropland": 0.598,
            "created_date": "2021-07-25 07:55:17.637329",
            "river": 0.589,
            "garden_plot": 0.265
        },
        {
            "mAP": 0.551,
            "rural_residential": 0.724,
            "arbor_woodland": 0.716,
            "paddy_field": 0.552,
            "irrigated_land": 0.791,
            "pond": 0.235,
            "TeamNames": "water",
            "lake": 0.772,
            "traffic_land": 0.688,
            "urban_residential": 0.785,
            "TeamMembers": "chen wisdom",
            "description": "swin",
            "Institute": "alibaba",
            "artificial_grassland": 0.085,
            "natural_grassland": 0.734,
            "date": "2021-08-16 06:25:51.769273",
            "shrub_land": 0.048,
            "industrial_land": 0.713,
            "dry_cropland": 0.513,
            "created_date": "2021-08-16 06:25:51.769273",
            "river": 0.589,
            "garden_plot": 0.318
        },
        {
            "mAP": 0.516,
            "rural_residential": 0.634,
            "arbor_woodland": 0.642,
            "paddy_field": 0.503,
            "irrigated_land": 0.766,
            "pond": 0.207,
            "TeamNames": "sjzhao",
            "lake": 0.751,
            "traffic_land": 0.66,
            "urban_residential": 0.761,
            "TeamMembers": "13151586369",
            "description": "ocrnet+hr48",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.128,
            "natural_grassland": 0.672,
            "date": "2021-08-06 11:21:03.900995",
            "shrub_land": 0.061,
            "industrial_land": 0.631,
            "dry_cropland": 0.456,
            "created_date": "2021-08-06 11:21:03.900995",
            "river": 0.56,
            "garden_plot": 0.302
        },
        {
            "mAP": 0.511,
            "rural_residential": 0.631,
            "arbor_woodland": 0.638,
            "paddy_field": 0.505,
            "irrigated_land": 0.763,
            "pond": 0.207,
            "TeamNames": "mf1923099",
            "lake": 0.742,
            "traffic_land": 0.678,
            "urban_residential": 0.77,
            "TeamMembers": "1,2,3,4",
            "description": "ocr48+ms",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.129,
            "natural_grassland": 0.646,
            "date": "2021-08-13 03:06:37.993625",
            "shrub_land": 0.026,
            "industrial_land": 0.622,
            "dry_cropland": 0.477,
            "created_date": "2021-08-13 03:06:37.993625",
            "river": 0.549,
            "garden_plot": 0.282
        },
        {
            "mAP": 0.51,
            "rural_residential": 0.598,
            "arbor_woodland": 0.605,
            "paddy_field": 0.51,
            "irrigated_land": 0.769,
            "pond": 0.2,
            "TeamNames": "thptai",
            "lake": 0.796,
            "traffic_land": 0.607,
            "urban_residential": 0.766,
            "TeamMembers": "Tran Huu Phuong Tai",
            "description": "Our method uses OCR_HRNet_MScales network as the base method to work on.\r\nThe training images are divided into multiple smaller images. The reason is to take the advantages of multiscale training while being able to train with high resolution. The network is trained with 9 different scales (0.25,0.5,1.0,2.0,2.5,3.0,3.5,4.0). \r\nFor the details of dividing raw images, we split an input image into 113 smaller parts with resolution 900x850. We slide the 900x850 mask over the image with the stride [450, 425] for x and y axis respectively.\r\nThe post processing stage is combining multiple smaller results images into one single images. The smoothing process is also applied to the final outputs to improve the overall quality to makeup for the dividing step in the beginning.",
            "Institute": "Sungkyunkwan University",
            "artificial_grassland": 0.139,
            "natural_grassland": 0.607,
            "date": "2021-08-11 08:11:08.869391",
            "shrub_land": 0.032,
            "industrial_land": 0.689,
            "dry_cropland": 0.465,
            "created_date": "2021-08-11 08:11:08.869391",
            "river": 0.621,
            "garden_plot": 0.252
        },
        {
            "mAP": 0.504,
            "rural_residential": 0.611,
            "arbor_woodland": 0.631,
            "paddy_field": 0.5,
            "irrigated_land": 0.782,
            "pond": 0.217,
            "TeamNames": "gaoziteng",
            "lake": 0.819,
            "traffic_land": 0.63,
            "urban_residential": 0.76,
            "TeamMembers": "a,b,c,d",
            "description": "fusion results",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.037,
            "natural_grassland": 0.578,
            "date": "2021-08-11 12:01:18.502128",
            "shrub_land": 0.006,
            "industrial_land": 0.672,
            "dry_cropland": 0.439,
            "created_date": "2021-08-11 12:01:18.502128",
            "river": 0.64,
            "garden_plot": 0.243
        },
        {
            "mAP": 0.501,
            "rural_residential": 0.63,
            "arbor_woodland": 0.626,
            "paddy_field": 0.427,
            "irrigated_land": 0.802,
            "pond": 0.223,
            "TeamNames": "yixinzhishui",
            "lake": 0.781,
            "traffic_land": 0.547,
            "urban_residential": 0.739,
            "TeamMembers": "Jac",
            "description": "The name of our team is yixinzhihui, from the University of Chinese Academy of Sciences. The version submitted this time is a preliminary test version. It mainly uses Efficientnet-b3 as the encoder, Unet as the decoder, and multi classification cross entropy as the loss function. We want to see where the benchwork for this dataset is.my email is xizhihao19@mails.ucas.ac.cn",
            "Institute": "University of Chinese Academy of Sciences",
            "artificial_grassland": 0.029,
            "natural_grassland": 0.609,
            "date": "2021-07-23 03:03:06.218716",
            "shrub_land": 0.068,
            "industrial_land": 0.648,
            "dry_cropland": 0.595,
            "created_date": "2021-07-23 03:03:06.218716",
            "river": 0.619,
            "garden_plot": 0.179
        },
        {
            "mAP": 0.497,
            "rural_residential": 0.614,
            "arbor_woodland": 0.642,
            "paddy_field": 0.501,
            "irrigated_land": 0.734,
            "pond": 0.22,
            "TeamNames": "hyf",
            "lake": 0.781,
            "traffic_land": 0.644,
            "urban_residential": 0.744,
            "TeamMembers": "Yifei Hu",
            "description": "Swin_transformer",
            "Institute": "Alibaba-inc",
            "artificial_grassland": 0.027,
            "natural_grassland": 0.573,
            "date": "2021-08-10 02:50:31.343541",
            "shrub_land": 0.046,
            "industrial_land": 0.684,
            "dry_cropland": 0.362,
            "created_date": "2021-08-10 02:50:31.343541",
            "river": 0.614,
            "garden_plot": 0.268
        },
        {
            "mAP": 0.484,
            "rural_residential": 0.563,
            "arbor_woodland": 0.599,
            "paddy_field": 0.523,
            "irrigated_land": 0.764,
            "pond": 0.153,
            "TeamNames": "zhaosijie",
            "lake": 0.804,
            "traffic_land": 0.525,
            "urban_residential": 0.747,
            "TeamMembers": "Chen Haoran, Hu Yifei, Zhao Sijie",
            "description": "ocrnet h18 1024x1024",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.032,
            "natural_grassland": 0.575,
            "date": "2021-08-13 07:08:24.457260",
            "shrub_land": 0.05,
            "industrial_land": 0.656,
            "dry_cropland": 0.493,
            "created_date": "2021-08-13 07:08:24.457260",
            "river": 0.6,
            "garden_plot": 0.171
        },
        {
            "mAP": 0.475,
            "rural_residential": 0.688,
            "arbor_woodland": 0.654,
            "paddy_field": 0.511,
            "irrigated_land": 0.752,
            "pond": 0.255,
            "TeamNames": "Amadeus",
            "lake": 0.751,
            "traffic_land": 0.573,
            "urban_residential": 0.751,
            "TeamMembers": "Zhe Chen",
            "description": "A remote sensing semantic segmentation method based on DeepLabV3+. In this result, we use ResNeXt-101 as the backbone and don't use any ensemble methods. Multi-scale training and testing are applied to get the final result. \r\n\r\ncode: https://github.com/LikeLy-Journey/SegmenTron\r\npaper: Rethinking Atrous Convolution for Semantic Image Segmentation",
            "Institute": "Nanjing University",
            "artificial_grassland": 0.042,
            "natural_grassland": 0.379,
            "date": "2021-08-14 19:39:11.434108",
            "shrub_land": 0.017,
            "industrial_land": 0.671,
            "dry_cropland": 0.406,
            "created_date": "2021-08-14 19:39:11.434108",
            "river": 0.537,
            "garden_plot": 0.131
        },
        {
            "mAP": 0.44,
            "rural_residential": 0.67,
            "arbor_woodland": 0.661,
            "paddy_field": 0.41,
            "irrigated_land": 0.717,
            "pond": 0.129,
            "TeamNames": "DeepBlueAI",
            "lake": 0.658,
            "traffic_land": 0.635,
            "urban_residential": 0.753,
            "TeamMembers": "ZhiPeng Luo, Ge Li",
            "description": "The method uses deep lab V3 + to segment RGB image semantically. The size of the cut image is 512 * 512 and the length of the sliding side is 256. The test image is cut by the same method. In training, the random clipping size is 449 * 449, the batch size is 48, and the number of iterations is 40K. The data enhancement includes random crop, random flip horizontal, random flip vertical, and photometricdistoration",
            "Institute": "DeepBlue Technology (Shanghai) Co., Ltd",
            "artificial_grassland": 0.05,
            "natural_grassland": 0.596,
            "date": "2021-08-12 12:48:16.176040",
            "shrub_land": 0.011,
            "industrial_land": 0.649,
            "dry_cropland": 0.139,
            "created_date": "2021-08-12 12:48:16.176040",
            "river": 0.456,
            "garden_plot": 0.075
        }
    ]
}